
#################################################################
#                                                               #
#            CrayPat-lite Performance Statistics                #
#                                                               #
#################################################################

CrayPat/X:  Version 22.06.0 Revision 4b5ab6256  05/21/22 02:03:49
Experiment:                  lite  lite-samples  
Number of PEs (MPI ranks):    256
Numbers of PEs per Node:      128  PEs on each of  2  Nodes
Numbers of Threads per PE:      1
Number of Cores per Socket:    64
Execution start time:  Thu Jun  1 10:52:02 2023
System name and speed:  nid001336  3.348 GHz (nominal)
AMD   Rome                 CPU  Family: 23  Model: 49  Stepping:  0
Core Performance Boost:  All 256 PEs have CPB capability



Avg Process Time:     4.52 secs             
High Memory:      24,675.0 MiBytes     96.4 MiBytes per PE
I/O Read Rate:    1.787794 MiBytes/sec      
I/O Write Rate:   0.968410 MiBytes/sec      

Notes for table 1:

  This table shows functions that have significant exclusive sample
    hits, averaged across ranks.
  For further explanation, use:  pat_report -v -O samp_profile ...

Table 1:  Profile by Function

  Samp% |  Samp | Imb. |  Imb. | Group
        |       | Samp | Samp% |  Function=[MAX10]
        |       |      |       |   PE=HIDE
       
 100.0% | 410.2 |   -- |    -- | Total
|-------------------------------------------------------------------
|  67.4% | 276.5 |   -- |    -- | USER
||------------------------------------------------------------------
||  28.2% | 115.5 | 21.5 | 15.8% | Particles3D::mover_PC_AoS
||  20.4% |  83.8 | 11.2 | 11.9% | EMfields3D::sumMoments_AoS
||   1.8% |   7.5 |  9.5 | 56.0% | Grid3DCU::get_safe_cell_and_weights
||   1.3% |   5.3 |  6.7 | 56.1% | get_field_components_for_cell
||==================================================================
|  31.6% | 129.6 |   -- |    -- | MPI
||------------------------------------------------------------------
||  12.8% |  52.6 | 24.4 | 31.8% | MPI_Waitall
||   7.1% |  29.2 | 21.8 | 43.0% | MPI_Isend
||   4.0% |  16.2 | 16.8 | 51.0% | MPI_Allreduce
||   3.1% |  12.8 | 15.2 | 54.4% | MPI_Waitany
||   1.9% |   7.9 |  9.1 | 53.7% | MPI_Irecv
||   1.3% |   5.5 |  6.5 | 54.2% | MPI_Cart_create
||==================================================================
|   1.0% |   4.0 |   -- |    -- | ETC
|===================================================================

Notes for table 2:

  This table shows functions, and line numbers within functions, that
    have significant exclusive sample hits, averaged across ranks.
  For further explanation, use:  pat_report -v -O samp_profile+src ...

Table 2:  Profile by Group, Function, and Line

  Samp% |  Samp | Imb. |  Imb. | Group
        |       | Samp | Samp% |  Function=[MAX10]
        |       |      |       |   Source
        |       |      |       |    Line
        |       |      |       |     PE=HIDE
       
 100.0% | 410.2 |   -- |    -- | Total
|------------------------------------------------------------------------
|  67.4% | 276.5 |   -- |    -- | USER
||-----------------------------------------------------------------------
||  28.2% | 115.5 |   -- |    -- | Particles3D::mover_PC_AoS
3|        |       |      |       |  Private/iPIC3D/particles/Particles3D.cpp
||||---------------------------------------------------------------------
4|||   2.6% |  10.8 |  8.2 | 43.2% | line.711
4|||   5.8% |  23.6 | 12.4 | 34.5% | line.725
4|||  15.1% |  61.9 | 17.1 | 21.7% | line.727
||||=====================================================================
||  20.4% |  83.8 |   -- |    -- | EMfields3D::sumMoments_AoS
3|        |       |      |       |  Private/iPIC3D/fields/EMfields3D.cpp
||||---------------------------------------------------------------------
4|||   4.1% |  16.9 |  9.1 | 35.3% | line.944
4|||  13.4% |  54.9 | 12.1 | 18.1% | line.946
||||=====================================================================
||   1.8% |   7.5 |   -- |    -- | Grid3DCU::get_safe_cell_and_weights
3|        |       |      |       |  Private/iPIC3D/include/Grid3DCU.h
||   1.3% |   5.3 |   -- |    -- | get_field_components_for_cell
3|        |       |      |       |  Private/iPIC3D/include/EMfields3D.h
||=======================================================================
|  31.6% | 129.6 |   -- |    -- | MPI
||-----------------------------------------------------------------------
||  12.8% |  52.6 | 24.4 | 31.8% | MPI_Waitall
||   7.1% |  29.2 | 21.8 | 43.0% | MPI_Isend
||   4.0% |  16.2 | 16.8 | 51.0% | MPI_Allreduce
||   3.1% |  12.8 | 15.2 | 54.4% | MPI_Waitany
||   1.9% |   7.9 |  9.1 | 53.7% | MPI_Irecv
||   1.3% |   5.5 |  6.5 | 54.2% | MPI_Cart_create
||=======================================================================
|   1.0% |   4.0 |   -- |    -- | ETC
|========================================================================

Observation:  MPI Grid Detection

    There appears to be point-to-point MPI communication in a 8 X 8 X 4
    grid pattern. The 31.6% of the total execution time spent in MPI
    functions might be reduced with a rank order that maximizes
    communication between ranks on the same node. The effect of several
    rank orders is estimated below.

    A file named MPICH_RANK_ORDER.Grid was generated along with this
    report and contains usage instructions and the Custom rank order
    from the following table.

    Rank Order    On-Node    On-Node  MPICH_RANK_REORDER_METHOD
                 Bytes/PE  Bytes/PE%  
                            of Total  
                            Bytes/PE  

        Custom  7.208e+09     90.03%  3
           SMP  7.199e+09     89.91%  1
          Fold  6.699e+09     83.68%  2
    RoundRobin  5.398e+09     67.42%  0


Observation:  MPI utilization

    The time spent processing MPI communications is relatively high. 
    Functions and callsites responsible for consuming the most time can
    be found in the table generated by pat_report -O callers+src (within
    the MPI group).


Notes for table 3:

  This table shows memory traffic for numa nodes, taking for each numa
    node the maximum value across nodes. It also shows the balance in
    memory traffic by showing the top 3 and bottom 3 node values.
  For further explanation, use:  pat_report -v -O mem_bw ...

Table 3:  Memory Bandwidth by Numanode

   Memory |     Read |    Write |   Thread |  Memory |  Memory | Numanode
  Traffic |   Memory |   Memory |     Time | Traffic | Traffic |  Node Id
   GBytes |  Traffic |  Traffic |          |  GBytes |       / |   PE=HIDE
          |   GBytes |   GBytes |          |   / Sec | Nominal | 
          |          |          |          |         |    Peak | 
|--------------------------------------------------------------------------
|     5.09 |     4.00 |     1.10 | 4.469738 |    1.14 |    0.6% | numanode.0
||-------------------------------------------------------------------------
||     5.18 |     4.06 |     1.13 | 4.462155 |    1.16 |    0.6% | nid.0
||     5.09 |     4.00 |     1.10 | 4.469738 |    1.14 |    0.6% | nid.1
||=========================================================================
|     4.00 |     3.18 |     0.82 | 4.468613 |    0.90 |    0.4% | numanode.1
||-------------------------------------------------------------------------
||     4.00 |     3.18 |     0.82 | 4.468613 |    0.90 |    0.4% | nid.1
||     3.92 |     3.11 |     0.82 | 4.463699 |    0.88 |    0.4% | nid.0
||=========================================================================
|     4.15 |     3.29 |     0.87 | 4.469594 |    0.93 |    0.5% | numanode.2
||-------------------------------------------------------------------------
||     4.16 |     3.28 |     0.88 | 4.461702 |    0.93 |    0.5% | nid.0
||     4.13 |     3.29 |     0.84 | 4.469594 |    0.92 |    0.5% | nid.1
||=========================================================================
|     4.81 |     3.81 |     1.00 | 4.468531 |    1.08 |    0.5% | numanode.3
||-------------------------------------------------------------------------
||     4.81 |     3.81 |     1.00 | 4.468531 |    1.08 |    0.5% | nid.1
||     4.71 |     3.73 |     0.98 | 4.461658 |    1.06 |    0.5% | nid.0
||=========================================================================
|     4.84 |     3.81 |     1.03 | 4.469568 |    1.08 |    0.5% | numanode.4
||-------------------------------------------------------------------------
||     4.83 |     3.81 |     1.02 | 4.469568 |    1.08 |    0.5% | nid.1
||     4.73 |     3.70 |     1.02 | 4.463476 |    1.06 |    0.5% | nid.0
||=========================================================================
|     3.72 |     2.94 |     0.77 | 4.468278 |    0.83 |    0.4% | numanode.5
||-------------------------------------------------------------------------
||     4.04 |     3.19 |     0.85 | 4.468278 |    0.90 |    0.4% | nid.1
||     3.90 |     3.11 |     0.79 | 4.462600 |    0.87 |    0.4% | nid.0
||=========================================================================
|     4.07 |     3.20 |     0.87 | 4.468192 |    0.91 |    0.4% | numanode.6
||-------------------------------------------------------------------------
||     4.07 |     3.20 |     0.87 | 4.468192 |    0.91 |    0.4% | nid.1
||     3.87 |     3.08 |     0.79 | 4.458926 |    0.87 |    0.4% | nid.0
||=========================================================================
|     4.87 |     3.84 |     1.03 | 4.470362 |    1.09 |    0.5% | numanode.7
||-------------------------------------------------------------------------
||     4.87 |     3.84 |     1.03 | 4.470362 |    1.09 |    0.5% | nid.1
||     4.75 |     3.74 |     1.01 | 4.462131 |    1.06 |    0.5% | nid.0
|==========================================================================

Notes for table 4:

  This table shows energy and power usage for the nodes with the
    maximum, mean, and minimum usage, as well as the sum of usage over
    all nodes.
    Energy and power for accelerators is also shown, if applicable.
  For further explanation, use:  pat_report -v -O program_energy ...

Table 4:  Program energy and power usage (from Cray PM)

   Node |      Node |  Process | Node Id
 Energy | Power (W) |     Time |  PE=HIDE
    (J) |           |          | 
       
  5,170 | 1,142.985 | 4.523244 | Total
|----------------------------------------
|  2,670 |   590.404 | 4.522327 | nid.0
|  2,500 |   552.589 | 4.524161 | nid.1
|========================================

Notes for table 5:

  This table show the average time and number of bytes read from each
    input file, taking the average over the number of ranks that read
    from the file.  It also shows the number of read operations, and
    average rates.
  For further explanation, use:  pat_report -v -O read_stats ...

Table 5:  File Input Stats by Filename

 Avg Read | Avg Read |   Read Rate | Number |    Avg |   Bytes/ | File Name=!x/^/(proc|sys)/
 Time per |  MiBytes | MiBytes/sec |     of |  Reads |     Call |  PE=HIDE
   Reader |      per |             | Reader |    per |          | 
     Rank |   Reader |             |  Ranks | Reader |          | 
          |     Rank |             |        |   Rank |          | 
|-----------------------------------------------------------------------------
| 0.002474 | 0.004422 |    1.787794 |    256 |    2.0 | 2,318.50 | ../inputfiles/256weak.inp
|=============================================================================

Notes for table 6:

  This table show the average time and number of bytes written to each
    output file, taking the average over the number of ranks that
    wrote to the file.  It also shows the number of write operations,
    and average rates.
  For further explanation, use:  pat_report -v -O write_stats ...

Table 6:  File Output Stats by Filename

      Avg |      Avg |  Write Rate | Number |     Avg | Bytes/ | File Name=!x/^/(proc|sys)/
    Write |    Write | MiBytes/sec |     of |  Writes |   Call |  PE=HIDE
 Time per |  MiBytes |             | Writer |     per |        | 
   Writer |      per |             |  Ranks |  Writer |        | 
     Rank |   Writer |             |        |    Rank |        | 
          |     Rank |             |        |         |        | 
|-----------------------------------------------------------------------------
| 0.004208 | 0.003986 |    0.947299 |    256 |    68.8 |  60.72 | _UnknownFile_
| 0.001175 | 0.023405 |   19.915653 |      1 | 1,131.0 |  21.70 | stdout
| 0.000606 | 0.001059 |    1.748110 |      1 |    41.0 |  27.07 | data256_weak/SimulationData.txt
|=============================================================================

Table 7:  Lustre File Information

                            File Path |    Stripe | Stripe | Stripe | OST list
                                      |      size | offset |  count | 
------------------------------------------------------------------------------
            ../inputfiles/256weak.inp | 1,048,576 |      0 |      1 | 12
      data256_weak/SimulationData.txt | 1,048,576 |      0 |      1 | 45
 data256_weak/ConservedQuantities.txt | 1,048,576 |      0 |      1 | 37
==============================================================================
Program invocation:
  /cfs/klemming/home/p/perttuj/Private/iPIC3D/build/./iPIC3D ../inputfiles/256weak.inp

For a complete report with expanded tables and notes, run:
  pat_report /cfs/klemming/home/p/perttuj/Private/iPIC3D/build/iPIC3D+197758-8605121s

For help identifying callers of particular functions:
  pat_report -O callers+src /cfs/klemming/home/p/perttuj/Private/iPIC3D/build/iPIC3D+197758-8605121s
To see the entire call tree:
  pat_report -O calltree+src /cfs/klemming/home/p/perttuj/Private/iPIC3D/build/iPIC3D+197758-8605121s

For interactive, graphical performance analysis, run:
  app2 /cfs/klemming/home/p/perttuj/Private/iPIC3D/build/iPIC3D+197758-8605121s

================  End of CrayPat-lite output  ==========================
